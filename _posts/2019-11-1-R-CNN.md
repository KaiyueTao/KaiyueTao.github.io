---
layout: post
title: R-CNN
categories: [learning]
author: Kaiyue Tao
tags: [Computer Vision, Learning, Object Detection]
math: true
mermaid: true
pin: true
---

**Author:** Ross Girshick, Jeff Donahue, etc  **UC Berkeley**

available at [Here](https://arxiv.org/abs/1311.2524)

## 主要贡献

1. first to show CNN can achieve **dramatically** higher performance on object detection （mAP = 53.7% on PASCAL VOC 2010，较之前有了大幅提升）
2. showed: superviesd pre-training on large dataset(ILSVRC) and then followed by domain-specific fune-tuning on a small dataset(PASCAL) **when data is scarce**, is an effective paradigm. [see](#training)
   
   *improves 8% by fine-tuning


## 网络结构

<img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g8n5xjaw0fj312w0e8gvb.jpg" />

输入图片后，首先提取2000个bottom-up region proposals，然后将每一个proposal输入CNN网络进行特征计算，最后使用linear SVM进行分类。

文章采用的CNN结构参照了[Krizhevsky]，之后他们又采用OxfordNet测试，将mAP提升到了66%，但是相应的网络复杂性带来了更长的时间消耗。

## Methods

1. combine region proposal with CNN (called R-CNN)
2. 否决了sliding-window，因为网络体积太大（在当时 5 layers）。故采用了生成regions的方法，生成2000个regions。
3. 使用CNN对图像进行特征提取，提取一个fiexed-length的vector。使用了affine image warping的方法，使得不同尺寸的region都可以输入CNN网络。
4. 利用category-specific linear SVMs进行分类。
5. error mode: buonding-box regression method，对于减少错误定位有重要作用。

## 具体流程

### 2 Modules

1. Region Proposals
    
    use Selective Search.

2. Feature Extraction
   
    4096-dimensional feature vector, computed by CNN.
    
    在这之前，需要解决的是对于不同size的region，如何将其变换到CNN输入的标准size。文章介绍了两种方法：

    <img src="https://tva1.sinaimg.cn/large/006y8mN6ly1g8n5xi9sh2j30yk0la1kx.jpg" />

   - tightest suqare with context
        
        我的理解是，对于一个region，选取能够包含它的最小的框，并且这个框的比例是符合CNN输入尺寸的。如上图中的B，可以看到框中出了包括了region，还同时包括了进了旁边的context。
    
   - warp

        大概就是把without context(C)的图拉伸至整个框。
    
    同时文章也考虑了region周围的additional context，通过一个参数padding(p)来定义额外的context。那么就会出现一种情况，当region足够大时，additional区域可能在image之外，此时则用image的均值代替每个像素。

### Test-time Detection

在得到了feature vector之后，对每个class都用SVM计算score。这里会有另一个问题，就是2000个region肯定有交叉的，如果都识别到了这个object，该怎么处理呢？

文章采用了一种greedy non-macimum suppression的方法，本质很简单：对于每一个class，如果某个region有一个与其相交的区域（Intersection-over-union, IoU）在这个class上得到了更高的分数，则拒绝这个region。

- Run-time Analysis：首先CNN的参数是全局共享的，所以无需对每个类都进行特定的参数学习；且feature vector相对纬度少，所以时间较快。（13s/image on GPU or 53s/image on CPU，现在应该更快）

### <span id="training">Training</span>

1. Supervised pre-training
   
   首先在大数据集上做与训练（ILSVRC2012），using Caffe CNN library。

2. Domain-specific Fine-tuning

    用wraped region proposals进行SGD训练。

    设定与ground truth box的IoU >0.5的region proposal为positive，其余为negative。
    
    - hyper-parameters: 
    
    learning rate = 0.001; batch-size = 128(32 positive windows and 96 background windows)

### Object Category Classfiers

一个值得讨论的问题就是，当一个region部分包含了一个class的时候，如何去定义其positive/negative？这里用到了上面提到的IoU，通过设定IoU的threshold来判断是否属于正例。文章测试了[0.1...0.5]区间的一系列threshole，最后选择了0.3。

Training data太大，当时的内存不够，故采用了[hard negative mining method]（http://cs.brown.edu/people/pfelzens/papers/lsvm-pami.pdf）。

### Ablation

为了找到哪一层对检测起到了至关重要的作用，文章比较了CNN without fune-tuning（即只在ILSVRC2012上训练）的performance，并通过逐层分析（pool5、fc6、fc7各自的performance），发现加上fc7后效果反而更差了，而fc7占了29%的parameters。

另一个发现是即使拿掉fc6，只留下pool5层，效果也没有下降太多，但是fc6和fc7的参数是最多的。去掉之后只剩下了6%的parameters，这样训练会快非常多。

这也说明了CNN的power非常强，将比之下全连接层参数多但是效果差，这也揭示了CNN的巨大潜能。

当加上**fune-tuning**之后，发现fune-tuning对两个fully connected层的提升非常大，而对于cnn层提升却一般般。这也表示cnn从pre-train的数据集学习到了基础知识，而fune-tuning提升则是针对于全连接层而言，学习到了domain-specific的分类特征。

### Bounding-Box Regression

为了减少localization error，文章训练了一个线性的model，在给每个region proposal打分的基础上- predict一个bounding box。即输入由CNN提取的features，输出bbox。

- input: (P<sup>i</sup>, G<sup>i</sup>)，其中P<sup>i</sup> = (P<sub>x</sub><sup>i</sup>, P<sub>y</sub><sup>i</sup>, P<sub>w</sub><sup>i</sup>, P<sub>h</sub><sup>i</sup>)，是region proposal的bbox，而G<sup>i</sup>则是对应的ground-truth。

通过将regression targets设为：

<center>t<sub>x</sub> = (G<sub>x</sub> - P<sub>x</sub>)/P<sub>w</sub></center>

<center>t<sub>y</sub> = (G<sub>y</sub> - P<sub>y</sub>)/P<sub>h</sub></center>

<center>t<sub>w</sub> = log(G<sub>w</sub>/P<sub>w</sub>)</center>

<center>t<sub>h</sub> = log(G<sub>h</sub>/P<sub>h</sub>)</center>

进行训练。当然这样在训练中归一化非常终于，且P的选取也会影响到结果，故文章只选取与ground-truth接近的P作为trainset（通过IoU为指标，>0.6）。

## Results

1. On PASCAL VOC 2010-12

    与UVA system比较：两者都使用了一样的region proposal方法。在分类上，UVA使用了SIFT，mAP为35.1%，而R-CNN高达53.3%。

2. On ILSVRC2013
   
    与OverFeat比较：OverFeat运用了sliding-window+CNN的方法，在ILSVR2013上，R-CNN的mAP=31.4%而OverFeat仅24.3%










